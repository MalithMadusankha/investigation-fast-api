{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "265bd2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 708.4258599329403\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the dataset from CSV\n",
    "data = pd.read_csv('Datasets/fraudDataset.csv')\n",
    "\n",
    "# Split the dataset into input features (X) and target variable (y)\n",
    "X = data.drop('fraud', axis=1)\n",
    "y = data['fraud']\n",
    "\n",
    "# Convert categorical variables into numerical using one-hot encoding\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a random forest regressor\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ed62db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Mean Squared Error: 1091.4814814814815\n",
      "K-Nearest Neighbors Regression Mean Squared Error: 714.4701234567901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Malith\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the dataset from CSV\n",
    "data = pd.read_csv('Datasets/fraudDataset.csv')\n",
    "\n",
    "# Split the dataset into input features (X) and target variable (y)\n",
    "X = data.drop('fraud', axis=1)\n",
    "y = data['fraud']\n",
    "\n",
    "# Convert categorical variables into numerical using one-hot encoding\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "logistic_model = LogisticRegression()\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set using Logistic Regression\n",
    "logistic_y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "# Evaluate the Logistic Regression model\n",
    "logistic_mse = mean_squared_error(y_test, logistic_y_pred)\n",
    "print(\"Logistic Regression Mean Squared Error:\", logistic_mse)\n",
    "\n",
    "# Train a K-Nearest Neighbors Regression model\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set using K-Nearest Neighbors Regression\n",
    "knn_y_pred = knn_model.predict(X_test)\n",
    "\n",
    "# Evaluate the K-Nearest Neighbors Regression model\n",
    "knn_mse = mean_squared_error(y_test, knn_y_pred)\n",
    "print(\"K-Nearest Neighbors Regression Mean Squared Error:\", knn_mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0001b609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=42)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "select_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cc93ff",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01c0974f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RandomForestRegressorModel.pickle']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# save model\n",
    "joblib.dump(select_model, 'RandomForestRegressorModel.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c678265",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0d2f658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "load_mode = joblib.load('RandomForestRegressorModel.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f286652",
   "metadata": {},
   "source": [
    "# Predict Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b0e7678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[44.924]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Load the trained model\n",
    "model = joblib.load('RandomForestRegressorModel.pickle')\n",
    "\n",
    "# Define the input data for prediction\n",
    "s1 = [\"western\", \"gampaha\", \"kiribathgoda\", \"may\", 2020]\n",
    "\n",
    "# Convert categorical variables into numerical using one-hot encoding\n",
    "S1 = pd.DataFrame([s1], columns=['provience', 'district', 'city', 'month', 'year'])\n",
    "S1 = pd.get_dummies(S1)\n",
    "\n",
    "# Ensure that the input data has the same features as the training data\n",
    "missing_cols = set(X.columns) - set(S1.columns)\n",
    "for col in missing_cols:\n",
    "    S1[col] = 0\n",
    "\n",
    "# Reorder the columns to match the training data\n",
    "S1 = S1[X.columns]\n",
    "\n",
    "# Predict on the input data\n",
    "S1_pred = model.predict(S1)\n",
    "print(S1_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00b86711",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "5 columns passed, passed data had 1 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_finalize_columns_and_data\u001b[1;34m(content, columns, dtype)\u001b[0m\n\u001b[0;32m    981\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 982\u001b[1;33m         \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_or_indexify_columns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    983\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_validate_or_indexify_columns\u001b[1;34m(content, columns)\u001b[0m\n\u001b[0;32m   1029\u001b[0m             \u001b[1;31m# caller's responsibility to check for this...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1030\u001b[1;33m             raise AssertionError(\n\u001b[0m\u001b[0;32m   1031\u001b[0m                 \u001b[1;34mf\"{len(columns)} columns passed, passed data had \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: 5 columns passed, passed data had 1 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9164\\3072060372.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ms1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m# Convert the sample to a DataFrame for one-hot encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mS1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'provience'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'district'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'city'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'month'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'year'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0mS1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mS1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    719\u001b[0m                         \u001b[1;31m# ndarray], Index, Series], Sequence[Any]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    720\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 721\u001b[1;33m                     arrays, columns, index = nested_data_to_arrays(\n\u001b[0m\u001b[0;32m    722\u001b[0m                         \u001b[1;31m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    723\u001b[0m                         \u001b[1;31m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mnested_data_to_arrays\u001b[1;34m(data, columns, index, dtype)\u001b[0m\n\u001b[0;32m    517\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m     \u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    520\u001b[0m     \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mto_arrays\u001b[1;34m(data, columns, dtype)\u001b[0m\n\u001b[0;32m    881\u001b[0m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_list_to_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 883\u001b[1;33m     \u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_finalize_columns_and_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    884\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    885\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_finalize_columns_and_data\u001b[1;34m(content, columns, dtype)\u001b[0m\n\u001b[0;32m    983\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;31m# GH#26429 do not raise user-facing AssertionError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcontents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobject_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: 5 columns passed, passed data had 1 columns"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Load the trained model\n",
    "model = joblib.load('RandomForestRegressorModel.pickle')\n",
    "\n",
    "# Define the input data for prediction\n",
    "s1 = [\n",
    "    [{provience:\"western\", district:\"gampaha\", city:\"kiribathgoda\", month:\"may\", year:2020}],\n",
    "    [{provience:\"western\", district:\"colombo\", city:\"colombo 01\", month:\"may\", year:2020}],\n",
    "    [{provience:\"western\", district:\"gampaha\", city:\"kiribathgoda\", month:\"jun\", year:2021}]\n",
    "]\n",
    "\n",
    "# Create an empty list to store the predictions\n",
    "predictions = []\n",
    "\n",
    "# Iterate over each sample in the input data\n",
    "for sample in s1:\n",
    "    # Convert the sample to a DataFrame for one-hot encoding\n",
    "    S1 = pd.DataFrame([sample], columns=['provience', 'district', 'city', 'month', 'year'])\n",
    "    S1 = pd.get_dummies(S1)\n",
    "\n",
    "    # Ensure that the input data has the same features as the training data\n",
    "    missing_cols = set(X.columns) - set(S1.columns)\n",
    "    for col in missing_cols:\n",
    "        S1[col] = 0\n",
    "\n",
    "    # Reorder the columns to match the training data\n",
    "    S1 = S1[X.columns]\n",
    "\n",
    "    # Predict on the input data\n",
    "    S1_pred = model.predict(S1)\n",
    "\n",
    "    # Append the prediction to the list\n",
    "    predictions.append(S1_pred)\n",
    "\n",
    "# Print the predictions\n",
    "for pred in predictions:\n",
    "    print(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a47f79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[44.924]\n",
      "[46.635]\n",
      "[37.96869048]\n",
      "46.635\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Load the trained model\n",
    "model = joblib.load('RandomForestRegressorModel.pickle')\n",
    "\n",
    "# Define the input data for prediction\n",
    "s1 = [\n",
    "    {\"provience\": \"western\", \"district\": \"gampaha\", \"city\": \"kiribathgoda\", \"month\": \"may\", \"year\": 2020},\n",
    "    {\"provience\": \"western\", \"district\": \"colombo\", \"city\": \"colombo 01\", \"month\": \"may\", \"year\": 2020},\n",
    "    {\"provience\": \"western\", \"district\": \"gampaha\", \"city\": \"kiribathgoda\", \"month\": \"jun\", \"year\": 2021}\n",
    "]\n",
    "\n",
    "# Create an empty list to store the predictions\n",
    "predictions = []\n",
    "\n",
    "# Iterate over each sample in the input data\n",
    "for sample in s1:\n",
    "    # Extract feature values from the sample dictionary\n",
    "    provience = sample[\"provience\"]\n",
    "    district = sample[\"district\"]\n",
    "    city = sample[\"city\"]\n",
    "    month = sample[\"month\"]\n",
    "    year = sample[\"year\"]\n",
    "\n",
    "    # Create a DataFrame for the sample\n",
    "    S1 = pd.DataFrame([[provience, district, city, month, year]],\n",
    "                      columns=['provience', 'district', 'city', 'month', 'year'])\n",
    "\n",
    "    # Convert categorical variables into numerical using one-hot encoding\n",
    "    S1 = pd.get_dummies(S1)\n",
    "\n",
    "    # Ensure that the input data has the same features as the training data\n",
    "    missing_cols = set(X.columns) - set(S1.columns)\n",
    "    for col in missing_cols:\n",
    "        S1[col] = 0\n",
    "\n",
    "    # Reorder the columns to match the training data\n",
    "    S1 = S1[X.columns]\n",
    "\n",
    "    # Predict on the input data\n",
    "    S1_pred = model.predict(S1)\n",
    "\n",
    "    # Append the prediction to the list\n",
    "    predictions.append(S1_pred)\n",
    "\n",
    "# Print the predictions\n",
    "for pred in predictions:\n",
    "    print(pred)\n",
    "predictions\n",
    "max_value = np.amax(predictions)\n",
    "\n",
    "print(max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8263e25c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>provience</th>\n",
       "      <th>district</th>\n",
       "      <th>city</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>western</td>\n",
       "      <td>colombo</td>\n",
       "      <td>colombo 1</td>\n",
       "      <td>jan</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>western</td>\n",
       "      <td>colombo</td>\n",
       "      <td>colombo 1</td>\n",
       "      <td>jan</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>western</td>\n",
       "      <td>colombo</td>\n",
       "      <td>colombo 2</td>\n",
       "      <td>jan</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>western</td>\n",
       "      <td>colombo</td>\n",
       "      <td>colombo 3</td>\n",
       "      <td>jan</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>western</td>\n",
       "      <td>colombo</td>\n",
       "      <td>colombo 4</td>\n",
       "      <td>jan</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>western</td>\n",
       "      <td>colombo</td>\n",
       "      <td>colombo 11</td>\n",
       "      <td>des</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>western</td>\n",
       "      <td>colombo</td>\n",
       "      <td>colombo 12</td>\n",
       "      <td>des</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>western</td>\n",
       "      <td>colombo</td>\n",
       "      <td>colombo 13</td>\n",
       "      <td>des</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>western</td>\n",
       "      <td>colombo</td>\n",
       "      <td>colombo 14</td>\n",
       "      <td>des</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>western</td>\n",
       "      <td>colombo</td>\n",
       "      <td>colombo 15</td>\n",
       "      <td>des</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    provience district        city month  year\n",
       "0     western  colombo   colombo 1   jan  2019\n",
       "1     western  colombo   colombo 1   jan  2019\n",
       "2     western  colombo   colombo 2   jan  2019\n",
       "3     western  colombo   colombo 3   jan  2019\n",
       "4     western  colombo   colombo 4   jan  2019\n",
       "..        ...      ...         ...   ...   ...\n",
       "187   western  colombo  colombo 11   des  2019\n",
       "188   western  colombo  colombo 12   des  2019\n",
       "189   western  colombo  colombo 13   des  2019\n",
       "190   western  colombo  colombo 14   des  2019\n",
       "191   western  colombo  colombo 15   des  2019\n",
       "\n",
       "[192 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Datasets/fraudDatasetColombo.csv')\n",
    "data[\"year\"] = 2019\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f759c765",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
